{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "It is recommended that the script be run in a Python 3 environment in Google Colab with GPU acceleration (T4) enabled. The script may take a long time to run on a CPU. Additionally, several version mismatch errors were noticed when running the script in a local environment (tested on a Windows machine). The script was tested to work fine in Google Colab.\n",
    "\n",
    "Additionally, Google Colab has no list dependency for Pyannote. Hence the following line should only be if the script is being executed in a local environment:\n",
    "\n",
    "```python\n",
    "%pip install pyannote\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Google Colab, install dependencies via the following commands:\n",
    "%pip install pydub\n",
    "%pip install -qq https://github.com/pyannote/pyannote-audio/archive/refs/heads/develop.zip #installs pyannote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio, display\n",
    "import json\n",
    "\n",
    "class SpeakerDiarization:\n",
    "    def __init__(self):\n",
    "        API_KEY = \"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\"\n",
    "        self.endtime = 0\n",
    "        self.timestamps = []\n",
    "        self.audionames = []\n",
    "        self.pipeline = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=API_KEY)\n",
    "        self.pipeline.to(torch.device(\"cuda\")) if torch.cuda.is_available() else self.pipeline\n",
    "\n",
    "    def merge_mp3_files_to_wav(self, mp3_dir, output_wav_file):\n",
    "        merged_audio = AudioSegment.silent(duration=150)\n",
    "        for file in os.listdir(mp3_dir):\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio = AudioSegment.from_wav(os.path.join(mp3_dir, file))\n",
    "                merged_audio += audio\n",
    "                merged_audio += AudioSegment.silent(duration=300)\n",
    "                self.endtime = self.endtime + audio.duration_seconds\n",
    "                self.timestamps.append(self.endtime)\n",
    "                self.audionames.append(file)\n",
    "        merged_audio.export(output_wav_file, format=\"wav\")\n",
    "\n",
    "    def diatrize_speakers(self, audio_file):\n",
    "        diarization = self.pipeline(audio_file)\n",
    "        speaker_info = {}\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            speaker_id = f\"speaker_{speaker}\"\n",
    "            if speaker_id not in speaker_info:\n",
    "                speaker_info[speaker_id] = {\n",
    "                    \"gender\": None,\n",
    "                    \"age-group\": None,\n",
    "                    \"samples\": []\n",
    "                }\n",
    "\n",
    "            #deducing the sample id\n",
    "            index = len(self.timestamps)\n",
    "            for i, timestamp in enumerate(self.timestamps):\n",
    "                if turn.end < timestamp:\n",
    "                    index = i + 1\n",
    "                    break\n",
    "\n",
    "            speaker_info[speaker_id][\"samples\"].append({\n",
    "                \"start\": turn.start,\n",
    "                \"end\": turn.end,\n",
    "                \"sample_id\": index,\n",
    "                \"sample_file\": self.audionames[index-1]\n",
    "            })\n",
    "        return speaker_info\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    speaker_diarization = SpeakerDiarization()\n",
    "    mp3_directory = \"./\"\n",
    "    output_wav_file = \"./output/merged_audio_wav.wav\"\n",
    "    speaker_diarization.merge_mp3_files_to_wav(mp3_directory, output_wav_file)\n",
    "    speaker_info = speaker_diarization.diatrize_speakers(output_wav_file)\n",
    "\n",
    "    # Prompt user to determine speaker gender\n",
    "    for speaker_id, info in speaker_info.items():\n",
    "        sample = info[\"samples\"][0]  # Take the first sample as representative\n",
    "        start, end, filename = sample[\"start\"], sample[\"end\"], sample[\"sample_file\"]\n",
    "\n",
    "        #Playing the audio file:\n",
    "        audio_path = os.path.join(mp3_directory, filename)\n",
    "        display(Audio(audio_path, autoplay=True))\n",
    "        print(f\"-->> Representative Sample for {speaker_id} in '{filename}' from {start:.1f}s to {end:.1f}s in the merged dataset.\")\n",
    "\n",
    "        #Gender Annotation\n",
    "        gender = input(\"Enter the gender (M/F): \").upper()\n",
    "        info[\"gender\"] = gender\n",
    "\n",
    "        #Age-group Annotation\n",
    "        age_group = input(\"Enter the expected age group (C [<10], T [11-18], A [19-39], R [40 - 59], E [>60]): \").upper()\n",
    "        info[\"age-group\"] = age_group\n",
    "\n",
    "    # Save speaker info to JSONL file\n",
    "    with open(\"speaker_info.jsonl\", \"w\") as f:\n",
    "        for speaker_id, info in speaker_info.items():\n",
    "            json.dump({speaker_id: info}, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    # Generate summary\n",
    "    total_samples = sum(len(info[\"samples\"]) for info in speaker_info.values())\n",
    "    total_speakers = len(speaker_info)\n",
    "    speakers_summary = [{\n",
    "        \"speaker\": speaker_id,\n",
    "        \"gender\": info[\"gender\"],\n",
    "        \"age-group\": info[\"age-group\"]\n",
    "    } for speaker_id, info in speaker_info.items()]\n",
    "\n",
    "    summary = {\n",
    "        \"total_samples\": total_samples,\n",
    "        \"total_speakers\": total_speakers,\n",
    "        \"speakers\": speakers_summary\n",
    "    }\n",
    "\n",
    "    # Save summary to JSON file\n",
    "    with open(\"summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "\n",
    "    print(\"Summary saved to summary.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
